# Development Mode - Iris

This document explains how to use Iris development mode to test functionalities without voice commands.

## Enable Development Mode

In the `App.tsx` file, change the `DEV_MODE` constant to `true`:

```typescript
// Development mode: change to true to activate test panel
const DEV_MODE = true;
```

## Test Screen

When `DEV_MODE` is enabled, the application shows a screen with two tabs:

### 1. Voice Tab ğŸ¤

Displays the normal voice command panel (`VoiceCommandPanel`).

**Functionality:**
- "Activate" button to start voice recognition
- "Stop" button to halt
- Visual state indicator (listening, processing, speaking)
- Shows transcript of what is heard
- Error handling with "Retry" button

### 2. Vision Tab ğŸ‘ï¸

Displays the vision AI test panel (`VisionTestPanel`).

**Functionality:**
- **Status indicator**: Shows if TensorFlow Lite models are loaded
  - âœ“ Models loaded (green)
  - â³ Loading models... (yellow)

- **ğŸ“ Analyze from Gallery**: 
  - Opens gallery selector
  - Allows selecting any saved image
  - Analyzes image with TensorFlow Lite
  - Shows preview of selected image
  - Generates description in Spanish

- **ğŸ“· Capture and Analyze**: 
  - Opens camera to take new photo
  - Analyzes captured photo
  - Shows photo preview
  - Generates description in Spanish

- **ğŸ¯ Analyze Current Scene**: 
  - Automatically captures with rear camera
  - Runs object detection model (COCO-SSD)
  - Generates description in Spanish
  - Shows result on screen

- **"Clear Results" button**: 
  - Appears after analysis
  - Clears results and preview for new test

- **Visual states**:
  - ğŸ” Analyzing image... (during process)
  - Preview of selected/captured image
  - Result with green background (success)
  - Error with red background (failure)

## Vision Test Flows

### Option 1: Analyze image from gallery (Recommended for development)

1. **Wait** for "âœ“ Models loaded" to appear
2. **Press** "ğŸ“ Analyze from Gallery"
3. **Select** an image from your gallery
4. **Wait** a few seconds while processing
5. **Read** the result on screen
6. **View** the analyzed image preview

### Option 2: Capture new photo

1. **Wait** for "âœ“ Models loaded" to appear
2. **Press** "ğŸ“· Capture and Analyze"
3. **Take** a photo with the camera
4. **Wait** a few seconds while processing
5. **Read** the result on screen
6. **View** the photo preview

### Option 3: Analyze current scene

1. **Wait** for "âœ“ Models loaded" to appear
2. **Point** the phone at some object
3. **Press** "ğŸ¯ Analyze Current Scene"
4. **Wait** a few seconds while processing
5. **Read** the result on screen

Example result:
```
I see a person, a chair, and a laptop
```

## Required Permissions

To use the vision panel you need:

- âœ… **Gallery permission**: To select saved images (requested automatically)
- âœ… **Camera permission**: To capture new photos or analyze current scene (requested automatically)

If permissions are denied, you'll see errors like:
```
Gallery access permission needed
Camera access permission needed
```

## Test Panel Architecture

```
TestScreen (page)
  â”œâ”€â”€ Voice Tab
  â”‚   â””â”€â”€ VoiceCommandPanel (molecule)
  â”‚       â””â”€â”€ useVoiceCommands (hook)
  â”‚
  â””â”€â”€ Vision Tab
      â””â”€â”€ VisionTestPanel (molecule)
          â””â”€â”€ useVisionService (hook)
              â”œâ”€â”€ ExpoCameraAdapter
              â””â”€â”€ TFLiteVisionAdapter
```

## Key Files

| File | Description |
|------|-------------|
| `App.tsx` | Entry point - enables/disables DEV_MODE |
| `TestScreen.tsx` | Test screen with tabs |
| `VisionTestPanel.tsx` | Vision test panel |
| `ImagePicker.tsx` | Component to select/capture images |
| `VoiceCommandPanel.tsx` | Voice command panel |

## Disable Development Mode

To return to normal mode (with wake word detection):

1. Open `App.tsx`
2. Change `DEV_MODE` to `false`:
   ```typescript
   const DEV_MODE = false;
   ```
3. Save and reload the app

## Debugging

To see vision logs:

```bash
# iOS
npx react-native log-ios

# Android
npx react-native log-android
```

Look for logs with prefix:
- `[VisionTestPanel]` - Test panel
- `[TFLiteVisionAdapter]` - Object detection
- `[ExpoCameraAdapter]` - Camera
- `[useVisionService]` - Vision hook

## Tests

The test panel has unit tests:

```bash
# Run panel tests
npm test VisionTestPanel.test.tsx

# Run all tests
npm test
```

Included tests:
- âœ… Correct rendering
- âœ… Model loading state
- âœ… Button disabled when not ready
- âœ… analyzeScene call
- âœ… Show successful result
- âœ… Show errors
- âœ… Clear results

## Troubleshooting

### Models don't load

**Symptom**: Stays on "â³ Loading models..."

**Solutions**:
1. Verify `react-native-fast-tflite` is installed
2. Check console logs
3. Restart the app

### Camera error

**Symptom**: "Camera not available"

**Solutions**:
1. Check permissions in device settings
2. Close other apps using the camera
3. Restart the app

### Doesn't detect objects

**Symptom**: "No objects detected"

**Possible causes**:
1. Low light in scene
2. Objects not in COCO-SSD's 80 categories
3. Objects too far or blurry
4. Confidence score too low (< 0.5)

**Solutions**:
1. Improve lighting
2. Try common objects (person, chair, laptop, phone, etc.)
3. Get closer to objects
4. Wait for camera to focus

### Crash when pressing "Analyze Scene"

**Solutions**:
1. Verify CameraCapture is mounted in App.tsx
2. Check models are loaded (âœ“ green)
3. Verify camera permissions
4. Look at error logs

## Future Improvements

- [ ] Button to manually take photo before analyzing
- [ ] Show bounding boxes in preview
- [ ] Adjust confidence threshold
- [ ] Debug mode with more details (coordinates, scores, etc.)
- [ ] Analysis history
- [ ] Export results to JSON
